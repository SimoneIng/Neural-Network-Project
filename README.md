# Neural-Network-Project

Consider the raw images from the MNIST dataset as input. This is a classification problem with C classes where C=10. 

- Extract a global dataset of N pairs, and divide it appropriately into training and test sets (consider at least 10,000 elements for the training set and 2,500 for the test set). Use resilient backpropagation (RProp) or ADAM as the weight update algorithm.
- Compare Convolutional and full-connected neural network performance at varying of the respective hyperparamenters , and considering the same weight update algorithm.

## Hyperparameters choice strategy 

- Random Search

## Data Normalization 

- Standardization

## Training and Evaluation Strategy 

- Mini Batch Training

## Chosen Weight Update Algorithm

- Adam 
- RProp

## Chosen Hyperparameters (DNN)

- Batch Size: 32, 64, 128
- N. of Layers: 1, 2, 3
- N. of Neurons per Layer: 64, 128, 256
- Activation Functions: Sigmoid, Softmax, ReLU
- Learning Rate: 0.01 / 0.001 / 0.0001
- N. of iterations:  

## Chosen Hyperparameters (CNN)
